3. Environmental Variables Selection

Factor selection
     I. Maxent point analysis (input distribution data swd formate with environmental factors' value, csv files), select top 30, the Highest Gain and Indispensable factors

Maxent setting: 
Maxent v3.4.4, 
check Creat response curves, Do jackknife to measure variables importance, 
output format = Logistic
check Random seed
Replicates = 3
Uncheck Write output grids
Leave other setting default

swd formate file example:
species	X	Y	aspectcos_mask	aspectsin_mask	bdod_0.5_mask
Ficus altissima	11509108.98	2676293.272	0.208117843	-0.154846191	126.2010803
Ficus altissima	10974836.87	2806350.872	0.121181607	0.029759424	106.302742
Ficus altissima	11126499.88	3012855.112	-0.312497437	-0.331383467	111.7556992


Analysis of variable contributions(Example)
Variable	Percent contribution	Permutation importance
northness_mask	8.6	1.9
geompit_mask	3.8	0.6
geomshoulder_mask	3.7	5.7
bio02_mask	3.3	5.6
ocd_60.100cm_mask	3.2	0.2

the Highest Gain and Indispensable factors(Example)
The following picture shows the results of the jackknife test of variable importance. The environmental variable with highest gain when used in isolation is northness_mask, 
which therefore appears to have the most useful information by itself. 
The environmental variable that decreases the gain the most when it is omitted is northness_mask, which therefore appears to have the most information that isn't present in the other variables. 
Values shown are averages over replicate runs.







     II. Pearson correlation

swd formate file example:
species	X	Y	aspectcos_mask	aspectsin_mask	bdod_0.5_mask
Ficus altissima	11509108.98	2676293.272	0.208117843	-0.154846191	126.2010803
Ficus altissima	10974836.87	2806350.872	0.121181607	0.029759424	106.302742
Ficus altissima	11126499.88	3012855.112	-0.312497437	-0.331383467	111.7556992

######R script#######
perfal <- read.csv("Ficus_altissima_5km_thin1_native_sus2_mercator_s.ValueCheck_cleaned_swd_top30.csv")

#####Correlation coefficient and correlation test in R
##https://statsandr.com/blog/correlation-coefficient-and-correlation-test-in-r/

#environment variables
dat <- perfal[c(4:33)]
round(cor(dat),
  digits = 6 # rounded to 6 decimals
)

# jnk=round(cor(dat),digits = 2)
# write.csv(jnk, file = "Correlation_43v.csv")
# na.omit(dat)
jnk=round(cor(na.omit(dat)),digits = 6)

# write.csv(jnk, file = "Correlation_56.csv")
write.csv(jnk, file = "Ficus_altissima_5km_thin1_native_sus2_mercator_s.ValueCheck_cleaned_swd_top30.Correlation.csv")

##### 2. Exploratory data analysis #####
# Correlations between variables
# install.packages("PerformanceAnalytics")

library(PerformanceAnalytics)

# Produce correlations plots using the chart.Correlation function in
# PerformanceAnalytics - edited here to remove asterisks indicating significance
# and density lines from histograms.

chart.Correlation <-
  function (R, histogram = TRUE, method=c("pearson", "kendall", "spearman"), ...)
  { # @author R Development Core Team
    # @author modified by Peter Carl
    # Visualization of a Correlation Matrix. On top the (absolute) value of the
    # correlation plus the result of the cor.test as stars. On bottom, the
    # bivariate scatterplots, with a fitted line
    
    x = checkData(R, method="matrix")
    
    if(missing(method)) method=method[1] #only use one
    cormeth <- method
    
    # Published at http://addictedtor.free.fr/graphiques/sources/source_137.R
    panel.cor <- function(x, y, digits=2, prefix="", use="pairwise.complete.obs", method=cormeth, cex.cor, ...)
    {
      usr <- par("usr"); on.exit(par(usr))
      par(usr = c(0, 1, 0, 1))
      r <- cor(x, y, use=use, method=method) # MG: remove abs here
      txt <- format(c(r, 0.123456789), digits=digits)[1]
      txt <- paste(prefix, txt, sep="")
      if(missing(cex.cor)) cex <- 0.8/strwidth(txt)
      
      test <- cor.test(as.numeric(x),as.numeric(y), method=method)
      # borrowed from printCoefmat
      # MG: add abs here and also include a 30% buffer for small numbers
      text(0.5, 0.5, txt, cex = cex * (abs(r) + .3) / 1.3)
    }
    f <- function(t) {
      dnorm(t, mean=mean(x), sd=sd.xts(x) )
    }
    
    #remove method from dotargs
    dotargs <- list(...)
    dotargs$method <- NULL
    rm(method)
    
    hist.panel = function (x, ...=NULL ) {
      par(new = TRUE)
      hist(x,
           col = "light gray",
           probability = TRUE,
           axes = FALSE,
           main = "",
           breaks = "FD")
      #lines(f, col="blue", lwd=1, lty=1) how to add gaussian normal overlay?
      rug(x)
    }
    
    # Draw the chart
    if(histogram)
      pairs(x, gap=0, lower.panel=panel.smooth, upper.panel=panel.cor, diag.panel=hist.panel)
    else
      pairs(x, gap=0, lower.panel=panel.smooth, upper.panel=panel.cor) 
  }


######################################################
# The NA can actually be due to 2 reasons. One is that there is a NA in your data. Another one is due to there being one of the values being constant. This results in standard deviation being equal to zero and hence the cor function returns NA.
######################################################

# Correlations between predictor variables

chart.Correlation(perfal[c(4:33)])

# Correlations between malar stripe scores
# chart.Correlation(scores) 
#If there is only one variable you could not run correlation analysis.

#####################################################
# Open a pdf file



pdf("Ficus_altissima_5km_thin1_native_sus2_mercator_s.ValueCheck_cleaned_swd_top30.Correlations.pdf")

# 2. Create a plot
plot(chart.Correlation(perfal[c(4:33)]))
# Close the pdf file
dev.off() 
################


#############################
Pearson Correlation result example:

	aspectcos_mask	aspectsin_mask	bdod_0.5_mask	bio02_mask
aspectcos_mask	1	0.102163	0.142821	0.030501
aspectsin_mask	0.102163	1	-0.096503	0.016027
bdod_0.5_mask	0.142821	-0.096503	1	-0.002767
bio02_mask	0.030501	0.016027	-0.002767	1

相关性等级用不同颜色代表
X>0.8	黄  高
0.7<X<0.8	红  较高
0.5<X<0.7	绿  中
X<0.5 	白  低

Correlation level represented by different colors:
X>0.8 Yellow High
0.7<X<0.8 Red Relatively high
0.5<X<0.7 Green Medium
X<0.5 White Low





     III. VIF (Variance Inflation Factor)

####VIF analysis#####
########Script based on “Collinearity and stepwise VIF selection” (https://beckmw.wordpress.com/2013/02/05/collinearity-and-stepwise-vif-selection/)##########
###########Most research papers consider a VIF (Variance Inflation Factor) > 10 as an indicator of multicollinearity, but some choose a more conservative threshold of 5 or even 2.5.##########

#install.packages("clusterGeneration")

require(MASS)
require(clusterGeneration)

vif_func<-function(in_frame,thresh=10,trace=T,...){

  library(fmsb)
  
  if(any(!'data.frame' %in% class(in_frame))) in_frame<-data.frame(in_frame)
  
  #get initial vif value for all comparisons of variables
  vif_init<-NULL
  var_names <- names(in_frame)
  for(val in var_names){
      regressors <- var_names[-which(var_names == val)]
      form <- paste(regressors, collapse = '+')
      form_in <- formula(paste(val, '~', form))
      vif_init<-rbind(vif_init, c(val, VIF(lm(form_in, data = in_frame, ...))))
      }
  vif_max<-max(as.numeric(vif_init[,2]), na.rm = TRUE)

  if(vif_max < thresh){
    if(trace==T){ #print output of each iteration
        prmatrix(vif_init,collab=c('var','vif'),rowlab=rep('',nrow(vif_init)),quote=F)
        cat('\n')
        cat(paste('All variables have VIF < ', thresh,', max VIF ',round(vif_max,2), sep=''),'\n\n')
        }
    return(var_names)
    }
  else{

    in_dat<-in_frame

    #backwards selection of explanatory variables, stops when all VIF values are below 'thresh'
    while(vif_max >= thresh){
      
      vif_vals<-NULL
      var_names <- names(in_dat)
        
      for(val in var_names){
        regressors <- var_names[-which(var_names == val)]
        form <- paste(regressors, collapse = '+')
        form_in <- formula(paste(val, '~', form))
        vif_add<-VIF(lm(form_in, data = in_dat, ...))
        vif_vals<-rbind(vif_vals,c(val,vif_add))
        }
      max_row<-which(vif_vals[,2] == max(as.numeric(vif_vals[,2]), na.rm = TRUE))[1]

      vif_max<-as.numeric(vif_vals[max_row,2])

      if(vif_max<thresh) break
      
      if(trace==T){ #print output of each iteration
        prmatrix(vif_vals,collab=c('var','vif'),rowlab=rep('',nrow(vif_vals)),quote=F)
        cat('\n')
        cat('removed: ',vif_vals[max_row,1],vif_max,'\n\n')
        flush.console()
        }

      in_dat<-in_dat[,!names(in_dat) %in% vif_vals[max_row,1]]

      }

    return(names(in_dat))
    
    }
  
  }


vif_func(in_frame=scores,thresh=1,trace=T) 

vif_func(in_frame=scores,thresh=1.5,trace=T) 

# [1] "cec_0.5cm_mask"          "dx_mask"                
# [3] "dy_mask"                 "eastness_mask"          
# [5] "geomflat_mask"           "geompit_mask"           
# [7] "geomshoulder_mask"       "nitrogen_100.200cm_mask"
# [9] "northness_mask"          "ocd_30.60cm_mask"       
# [11] "prec01_mask"             "tpi_mask"               
# [13] "wv0033_60.100cm_mask"   

vif_func(in_frame=scores,thresh=2,trace=T) 

vif_func(in_frame=scores,thresh=2.5,trace=T) 

vif_func(in_frame=scores,thresh=5,trace=T)         

vif_func(in_frame=scores,thresh=10,trace=T)




     IV. Screen based on upper three steps

Priority screening:
1. Highest Gain and Indispensable factors
2. VIF top
3. Pearson correlation



     V. Maxent layer analysis (input distribution data csv files, and complete environmental factors' layer asc files) based response curve and contribution

根据响应曲线和贡献值，逐步筛选为5个或5个以内的重要影响因子
Gradually screen out five or less important influencing factors based on the response curve and contribution value.

Curve1: The curves show how the logistic prediction changes as each environmental variable is varied, keeping all other environmental variables at their average sample value.
Curve2: In contrast to the above marginal response curves, each of the following curves represents a different model, namely, a Maxent model created using only the corresponding variable. 

筛选掉/去除掉 Curve1和Curve2明显不同的因素，明显不同代表该因素极大受到其他因素影响
Eliminate/Remove factors where Curve1 and Curve2 are significantly different, indicating that the factor is greatly influenced by other factors.







